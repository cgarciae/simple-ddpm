{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4347f7df",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import jax\n",
    "from IPython import get_ipython\n",
    "\n",
    "from utils import setup_config\n",
    "\n",
    "print(jax.devices())\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EMAConfig:\n",
    "    decay: float = 0.995\n",
    "    update_every: int = 10\n",
    "    update_after_step: int = 100\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DiffusionConfig:\n",
    "    schedule: str = \"cosine\"\n",
    "    beta_start: float = 3e-4\n",
    "    beta_end: float = 0.5\n",
    "    timesteps: int = 1_000\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OptimizerConfig:\n",
    "    lr_start: float = 2e-5\n",
    "    drop_1_mult: float = 1.0\n",
    "    drop_2_mult: float = 1.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 500\n",
    "    total_samples: int = 5_000_000\n",
    "    loss_type: str = \"mae\"\n",
    "    dataset: str = \"cartoonset\"\n",
    "    viz: str = \"matplotlib\"\n",
    "    model: str = \"stable_unet\"\n",
    "    eval_every: int = 2000\n",
    "    log_every: int = 200\n",
    "    ema: EMAConfig = EMAConfig()\n",
    "    schedule: DiffusionConfig = DiffusionConfig()\n",
    "    diffusion: DiffusionConfig = DiffusionConfig()\n",
    "    optimizer: OptimizerConfig = OptimizerConfig()\n",
    "\n",
    "    @property\n",
    "    def steps_per_epoch(self) -> int:\n",
    "        return self.total_samples // (self.epochs * self.batch_size)\n",
    "\n",
    "    @property\n",
    "    def total_steps(self) -> int:\n",
    "        return self.total_samples // self.batch_size\n",
    "\n",
    "\n",
    "config = setup_config(Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6712af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datasets.load import load_dataset\n",
    "\n",
    "\n",
    "def get_data(dataset: str, batch_size: int):\n",
    "    if dataset == \"mnist\":\n",
    "        hfds = load_dataset(\"mnist\", split=\"train\")\n",
    "        X = np.stack(hfds[\"image\"])[..., None]\n",
    "        ds = tf.data.Dataset.from_tensor_slices(X.astype(np.float32))\n",
    "    elif dataset == \"pokemon\":\n",
    "        hfds = load_dataset(\"lambdalabs/pokemon-blip-captions\", split=\"train\")\n",
    "        hfds = hfds.map(\n",
    "            lambda sample: {\"image\": sample[\"image\"].resize((64 + 16, 64 + 16))},\n",
    "            remove_columns=[\"text\"],\n",
    "            batch_size=96,\n",
    "        )\n",
    "        X = np.stack(hfds[\"image\"])\n",
    "        ds = tf.data.Dataset.from_tensor_slices(X.astype(np.float32))\n",
    "    elif dataset == \"cartoonset\":\n",
    "        hfds = load_dataset(\"cgarciae/cartoonset\", \"10k\", split=\"train\")\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            lambda: hfds,\n",
    "            output_signature={\n",
    "                \"img_bytes\": tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "            },\n",
    "        )\n",
    "\n",
    "        def process_fn(x):\n",
    "            x = tf.image.decode_png(x[\"img_bytes\"], channels=3)\n",
    "            x = tf.cast(x, tf.float32)\n",
    "            x = tf.image.resize(x, (128, 128))\n",
    "            return x\n",
    "\n",
    "        ds = ds.map(process_fn)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset {dataset}\")\n",
    "\n",
    "    ds = ds.map(lambda x: x / 127.5 - 1.0)\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.shuffle(seed=42, buffer_size=1_000)\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "ds = get_data(config.dataset, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ebaa3c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from einop import einop\n",
    "\n",
    "from utils import render_image, show\n",
    "\n",
    "x_sample = ds.as_numpy_iterator().next()\n",
    "num_channels = x_sample.shape[-1]\n",
    "\n",
    "n_rows = 4\n",
    "n_cols = 7\n",
    "x = x_sample[: n_rows * n_cols]\n",
    "plt.figure(figsize=(3 * n_cols, 3 * n_rows))\n",
    "x = einop(x, \"(row col) h w c -> (row h) (col w) c\", row=n_rows, col=n_cols)\n",
    "render_image(x)\n",
    "show(\"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3758d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.struct import PyTreeNode\n",
    "\n",
    "\n",
    "def expand_to(a, b):\n",
    "    new_shape = a.shape + (1,) * (b.ndim - a.ndim)\n",
    "    return a.reshape(new_shape)\n",
    "\n",
    "\n",
    "class GaussianDiffusion(PyTreeNode):\n",
    "    betas: jnp.ndarray\n",
    "    alphas: jnp.ndarray\n",
    "    alpha_bars: jnp.ndarray\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, betas: jnp.ndarray) -> \"GaussianDiffusion\":\n",
    "        return cls(\n",
    "            betas=betas,\n",
    "            alphas=1.0 - betas,\n",
    "            alpha_bars=jnp.cumprod(1.0 - betas),\n",
    "        )\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def forward_diffusion(process: GaussianDiffusion, key, x0, t):\n",
    "    alpha_bars = expand_to(process.alpha_bars[t], x0)\n",
    "    noise = jax.random.normal(key, x0.shape)\n",
    "    xt = jnp.sqrt(alpha_bars) * x0 + jnp.sqrt(1.0 - alpha_bars) * noise\n",
    "    return xt, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_schedule(beta_start, beta_end, timesteps, exponent=2.0, **kwargs):\n",
    "    betas = jnp.linspace(0, 1, timesteps) ** exponent\n",
    "    return betas * (beta_end - beta_start) + beta_start\n",
    "\n",
    "\n",
    "def sigmoid_schedule(beta_start, beta_end, timesteps, **kwargs):\n",
    "    betas = jax.nn.sigmoid(jnp.linspace(-6, 6, timesteps))\n",
    "    return betas * (beta_end - beta_start) + beta_start\n",
    "\n",
    "\n",
    "def cosine_schedule(beta_start, beta_end, timesteps, s=0.008, **kwargs):\n",
    "    x = jnp.linspace(0, timesteps, timesteps + 1)\n",
    "    ft = jnp.cos(((x / timesteps) + s) / (1 + s) * jnp.pi * 0.5) ** 2\n",
    "    alphas_cumprod = ft / ft[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    betas = jnp.clip(betas, 0.0001, 0.9999)\n",
    "    betas = (betas - betas.min()) / (betas.max() - betas.min())\n",
    "    return betas * (beta_end - beta_start) + beta_start\n",
    "\n",
    "\n",
    "# TODO: create a plot for each schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f273e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if config.diffusion.schedule == \"polynomial\":\n",
    "    schedule = polynomial_schedule\n",
    "elif config.diffusion.schedule == \"sigmoid\":\n",
    "    schedule = sigmoid_schedule\n",
    "elif config.diffusion.schedule == \"cosine\":\n",
    "    schedule = cosine_schedule\n",
    "else:\n",
    "    raise ValueError(f\"Unknown schedule {config.diffusion.schedule}\")\n",
    "\n",
    "betas = schedule(\n",
    "    config.diffusion.beta_start, config.diffusion.beta_end, config.diffusion.timesteps\n",
    ")\n",
    "process = GaussianDiffusion.create(betas)\n",
    "n_rows = 2\n",
    "n_cols = 7\n",
    "\n",
    "_, (ax_img, ax_plot) = plt.subplots(2, 1, figsize=(3 * n_cols, 3 * n_rows))\n",
    "\n",
    "t = jnp.linspace(0, config.diffusion.timesteps, n_cols).astype(int)\n",
    "x = einop(x_sample[0], \"h w c -> b h w c\", b=n_cols)\n",
    "x, _ = forward_diffusion(process, jax.random.PRNGKey(0), x, t)\n",
    "x = einop(x, \"col h w c -> h (col w) c\", col=n_cols)\n",
    "render_image(x, ax=ax_img)\n",
    "\n",
    "linear = polynomial_schedule(\n",
    "    betas.min(), betas.max(), config.diffusion.timesteps, exponent=1.0\n",
    ")\n",
    "ax_plot.plot(linear, label=\"linear\", color=\"black\", linestyle=\"dotted\")\n",
    "ax_plot.plot(betas)\n",
    "for s in [\"top\", \"bottom\", \"left\", \"right\"]:\n",
    "    ax_plot.spines[s].set_visible(False)\n",
    "\n",
    "show(\"betas_schedule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from flax.training import train_state\n",
    "\n",
    "from utils import EMA\n",
    "\n",
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "    ema: EMA\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, *, apply_fn, params, tx, ema: EMA, **kwargs):\n",
    "        return super().create(\n",
    "            apply_fn=apply_fn, params=params, tx=tx, ema=ema, **kwargs\n",
    "        )\n",
    "\n",
    "    def ema_update(self, step: int) -> \"TrainState\":\n",
    "        ema = self.ema.update(step, self.params)\n",
    "        return self.replace(ema=ema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe0a895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "from jax_metrics.metrics import Mean, Metrics\n",
    "\n",
    "from models.mlp_mixer import MLPMixer\n",
    "from models.simple_cnn import SimpleCNN\n",
    "from models.simple_unet import SimpleUNet\n",
    "from models.unet_lucid import UNet\n",
    "from models.unet_stable import UNet2DConfig, UNet2DModule\n",
    "\n",
    "if config.model == \"stable_unet\":\n",
    "    module = UNet2DModule(\n",
    "        UNet2DConfig(\n",
    "            out_channels=num_channels,\n",
    "            down_block_types=(\n",
    "                \"DownBlock2D\",\n",
    "                \"DownBlock2D\",\n",
    "                \"DownBlock2D\",\n",
    "                \"CrossAttnDownBlock2D\",\n",
    "            ),\n",
    "            up_block_types=(\n",
    "                \"CrossAttnUpBlock2D\",\n",
    "                \"UpBlock2D\",\n",
    "                \"UpBlock2D\",\n",
    "                \"UpBlock2D\",\n",
    "            ),\n",
    "            block_out_channels=(\n",
    "                128,\n",
    "                128,\n",
    "                256,\n",
    "                256,\n",
    "            ),\n",
    "            cross_attention_dim=256,\n",
    "        )\n",
    "    )\n",
    "elif config.model == \"lucid_unet\":\n",
    "    module = UNet(dim=64, dim_mults=(1, 2, 4), channels=num_channels)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model: '{config.model}'\")\n",
    "\n",
    "variables = module.init(jax.random.PRNGKey(42), x_sample[:1], jnp.array([0]))\n",
    "tx = optax.chain(\n",
    "    optax.clip_by_global_norm(1.0),\n",
    "    optax.adamw(\n",
    "        optax.piecewise_constant_schedule(\n",
    "            config.optimizer.lr_start,\n",
    "            {\n",
    "                int(config.total_steps * 1 / 3): config.optimizer.drop_1_mult,\n",
    "                int(config.total_steps * 2 / 3): config.optimizer.drop_2_mult,\n",
    "            },\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "state: TrainState = TrainState.create(\n",
    "    apply_fn=module.apply,\n",
    "    params=variables[\"params\"],\n",
    "    tx=tx,\n",
    "    ema=EMA.create(\n",
    "        params=variables[\"params\"],\n",
    "        decay=config.ema.decay,\n",
    "        update_every=config.ema.update_every,\n",
    "        update_after_step=config.ema.update_after_step,\n",
    "    ),\n",
    ")\n",
    "metrics = Metrics(\n",
    "    [\n",
    "        Mean(name=\"loss\").map_arg(loss=\"values\"),\n",
    "        Mean(name=\"ema_loss\").map_arg(ema_loss=\"values\"),\n",
    "    ]\n",
    ").init()\n",
    "\n",
    "print(module.tabulate(jax.random.PRNGKey(42), x_sample[:1], jnp.array([0]), depth=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95abcafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def reverse_diffusion(process: GaussianDiffusion, key, x, noise_hat, t):\n",
    "    betas = expand_to(process.betas[t], x)\n",
    "    alphas = expand_to(process.alphas[t], x)\n",
    "    alpha_bars = expand_to(process.alpha_bars[t], x)\n",
    "\n",
    "    z = jnp.where(\n",
    "        expand_to(t, x) > 0, jax.random.normal(key, x.shape), jnp.zeros_like(x)\n",
    "    )\n",
    "    noise_scaled = betas / jnp.sqrt(1.0 - alpha_bars) * noise_hat\n",
    "    x = (x - noise_scaled) / jnp.sqrt(alphas) + jnp.sqrt(betas) * z\n",
    "    return x\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnames=[\"return_all\"])\n",
    "def sample(key, x0, ts, params, process, *, return_all=True):\n",
    "    print(\"compiling 'sample' ...\")\n",
    "    keys = jax.random.split(key, len(ts))\n",
    "    ts = einop(ts, \"t -> t b\", b=x0.shape[0])\n",
    "\n",
    "    def scan_fn(x, inputs):\n",
    "        t, key = inputs\n",
    "        noise_hat = module.apply({\"params\": params}, x, t)\n",
    "        x = reverse_diffusion(process, key, x, noise_hat, t)\n",
    "        out = x if return_all else None\n",
    "        return x, out\n",
    "\n",
    "    x, xs = jax.lax.scan(scan_fn, x0, (ts, keys))\n",
    "    return xs if return_all else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c74af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if config.loss_type == \"mse\":\n",
    "    loss_metric = lambda a, b: jnp.mean((a - b) ** 2)\n",
    "elif config.loss_type == \"mae\":\n",
    "    loss_metric = lambda a, b: jnp.mean(jnp.abs(a - b))\n",
    "else:\n",
    "    raise ValueError(f\"Unknown loss type {config.loss_type}\")\n",
    "\n",
    "\n",
    "def loss_fn(params, xt, t, noise):\n",
    "    noise_hat = state.apply_fn({\"params\": params}, xt, t)\n",
    "    return loss_metric(noise, noise_hat)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(key, x, state: TrainState, metrics: Metrics, process: GaussianDiffusion):\n",
    "    print(\"compiling 'train_step' ...\")\n",
    "    key_t, key_diffusion, key = jax.random.split(key, 3)\n",
    "    t = jax.random.uniform(\n",
    "        key_t, (x.shape[0],), minval=0, maxval=config.diffusion.timesteps - 1\n",
    "    ).astype(jnp.int32)\n",
    "    xt, noise = forward_diffusion(process, key_diffusion, x, t)\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(state.params, xt, t, noise)\n",
    "    ema_loss = loss_fn(state.ema.params, xt, t, noise)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics = metrics.update(loss=loss, ema_loss=ema_loss)\n",
    "    logs = metrics.compute()\n",
    "    return logs, key, state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import log_metrics\n",
    "\n",
    "print(jax.devices())\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "axs_diffusion = None\n",
    "ds_iterator = ds.as_numpy_iterator()\n",
    "logs = {}\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb09f87",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "for step in tqdm(\n",
    "    range(step, config.total_steps), total=config.total_steps, unit=\"step\"\n",
    "):\n",
    "\n",
    "    if step % config.eval_every == 0:\n",
    "        # --------------------\n",
    "        # visualize progress\n",
    "        # --------------------\n",
    "        print(\"Sampling...\")\n",
    "        n_rows = 3\n",
    "        n_cols = 5\n",
    "        viz_key = jax.random.PRNGKey(1)\n",
    "        x = jax.random.normal(viz_key, (n_rows * n_cols, *x_sample.shape[1:]))\n",
    "\n",
    "        ts = np.arange(config.diffusion.timesteps)[::-1]\n",
    "        xf = np.asarray(\n",
    "            sample(viz_key, x, ts, state.ema.params, process, return_all=False)\n",
    "        )\n",
    "        xf = einop(xf, \"(row col) h w c -> (row h) (col w) c\", row=n_rows, col=n_cols)\n",
    "\n",
    "        if axs_diffusion is None or get_ipython() or config.viz == \"wandb\":\n",
    "            plt.figure(figsize=(3 * n_cols, 3 * n_rows))\n",
    "            axs_diffusion = plt.gca()\n",
    "\n",
    "        axs_diffusion.clear()\n",
    "        render_image(xf, ax=axs_diffusion)\n",
    "        show(\"training_samples\", step=step)\n",
    "\n",
    "    if step % config.log_every == 0:\n",
    "        print()  # newline\n",
    "        log_metrics(logs, step)\n",
    "        metrics = metrics.reset()\n",
    "\n",
    "    # --------------------\n",
    "    # trainig step\n",
    "    # --------------------\n",
    "    x = ds_iterator.next()\n",
    "    logs, key, state, metrics = train_step(key, x, state, metrics, process)\n",
    "    state = state.ema_update(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211464b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 3\n",
    "n_cols = 5\n",
    "viz_key = jax.random.PRNGKey(1)\n",
    "x = jax.random.normal(viz_key, (n_rows * n_cols, *x_sample.shape[1:]))\n",
    "\n",
    "ts = np.arange(config.diffusion.timesteps)[::-1]\n",
    "xf = np.asarray(sample(viz_key, x, ts, state.ema.params, process, return_all=False))\n",
    "xf = einop(xf, \"(row col) h w c -> (row h) (col w) c\", row=n_rows, col=n_cols)\n",
    "\n",
    "plt.figure(figsize=(3 * n_cols, 3 * n_rows))\n",
    "render_image(xf)\n",
    "show(\"final_samples\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
